{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentence = 'Again, human interaction needs to have resolutions. Your reps cannot BLAME the system and shrug off being able to help. Let alone blame the system and not know WHY the system makes indiscriminate decisions.'\n",
    "tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "pos_word_list=[]\n",
    "neu_word_list=[]\n",
    "neg_word_list=[]\n",
    "\n",
    "for word in tokenized_sentence:\n",
    "    if (sid.polarity_scores(word)['compound']) >= 0.1:\n",
    "        print(sid.polarity_scores(word))\n",
    "        pos_word_list.append(word)\n",
    "    elif (sid.polarity_scores(word)['compound']) <= -0.1:\n",
    "        neg_word_list.append(word)\n",
    "    else:\n",
    "        neu_word_list.append(word)                \n",
    "\n",
    "print('Positive:',pos_word_list)        \n",
    "print('Neutral:',neu_word_list)    \n",
    "print('Negative:',neg_word_list) \n",
    "score = sid.polarity_scores(sentence)\n",
    "print('\\nScores:', score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
